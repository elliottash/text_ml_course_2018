{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "import warnings; warnings.simplefilter('ignore')\n",
    "# set this to your working directory\n",
    "WORKING_DIR = '/home/elliott/Dropbox/_Ash_Teaching/2018-09 - Bocconi - Text Data and ML/code'\n",
    "import os\n",
    "os.chdir(WORKING_DIR)\n",
    "%matplotlib notebook\n",
    "\n",
    "import pandas as pd\n",
    "df1 = pd.read_csv('death-penalty-cases.csv')\n",
    "Xraw = pd.read_pickle('X.pkl')\n",
    "vocab = pd.read_pickle('vocab.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('texas', 15.157060829812988),\n",
       " ('views', 14.162723136391637),\n",
       " ('penalty_quot', 13.987539799853783),\n",
       " ('death_penalty_quot', 13.882195791855306),\n",
       " ('death_penalty_law', 13.796881088968187),\n",
       " ('penalty_law', 13.786978075466232),\n",
       " ('vote_death_penalty', 13.200971205191937),\n",
       " ('vote_death', 13.198037293642914),\n",
       " ('vote', 12.90649508072566),\n",
       " ('views_death', 12.742941138262612),\n",
       " ('act', -12.866619826449174),\n",
       " ('aedpa', -12.908893663389573),\n",
       " ('antiterrorism', -13.023546041592605),\n",
       " ('antiterrorism_effective', -13.047299668279841),\n",
       " ('antiterrorism_effective_death', -13.047299668279841),\n",
       " ('death_penalty_act', -13.492546471661809),\n",
       " ('penalty_act', -13.492546471661809),\n",
       " ('effective', -13.662906539833477),\n",
       " ('effective_death', -14.225782953608991),\n",
       " ('effective_death_penalty', -14.225782953608991)]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###\n",
    "# OLS Regression\n",
    "###\n",
    "\n",
    "# list of words from our vectorizer\n",
    "vocab = [w.replace(' ', '_') for w in vocab]\n",
    "         \n",
    "# convert frequency counts to dataframe\n",
    "df4 = pd.DataFrame(Xraw.todense(),\n",
    "                   columns=vocab)\n",
    "\n",
    "# import statsmodels package for R-like regression formulas\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "# add metadata\n",
    "df4['Y'] = df1['citeCount'] # cites to this opinion\n",
    "df4['courtfe'] = df1['court_id']   # court fixed effect\n",
    "df4['yearfe'] = df1['year']        # year fixed effect\n",
    "\n",
    "# empty lists for t-statistics and coefficients\n",
    "tstats, betas = [], []\n",
    "\n",
    "for xvar in vocab: # loop through the words in vocab\n",
    "    if any([c.isdigit() for c in xvar]) or 'hellip' in xvar:\n",
    "        tstats.append(0)\n",
    "        betas.append(0)\n",
    "        continue\n",
    "    model = smf.ols('Y ~ %s' % xvar,data=df4)                \n",
    "    result = model.fit() \n",
    "    tstats.append(result.tvalues[1])\n",
    "    betas.append(result.params[1])\n",
    "            \n",
    "# save estimates\n",
    "pd.to_pickle(tstats,'tstats.pkl')    \n",
    "pd.to_pickle(betas,'betas.pkl')\n",
    "\n",
    "# zip up words and t-statistics\n",
    "stats = list(zip(vocab,tstats))\n",
    "stats.sort(key = lambda x: x[1], reverse=True) # sort by second item (tstats)\n",
    "stats[:10] + stats[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.50905345213711373"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Overfitting\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "m = 100\n",
    "X = 6 * np.random.rand(m,1) - 3\n",
    "y = 0.5 * X ** 2 + X + 2 + np.random.randn(m,1)\n",
    "y = y.ravel()\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "poly_2 = PolynomialFeatures(degree=2) # also adds interactions\n",
    "X_poly_2 = poly_2.fit_transform(X)\n",
    "\n",
    "\n",
    "poly_300 = PolynomialFeatures(degree=300) \n",
    "X_poly_300 = poly_300.fit_transform(X)\n",
    "\n",
    "\n",
    "lin_reg = LinearRegression()\n",
    "cross_val_score(lin_reg, X, y, cv=3, n_jobs=3).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.80327148960479178"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(lin_reg, X_poly_2, y, cv=3, n_jobs=3).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.631660878146161e+17"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(lin_reg, X_poly_300, y, cv=3, n_jobs=3).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.50889492877877351"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lasso\n",
    "from sklearn.linear_model import Lasso\n",
    "lasso_reg = Lasso(alpha=0.1)\n",
    "cross_val_score(lasso_reg,X,y).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.50917225428549584"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ridge\n",
    "from sklearn.linear_model import Ridge, SGDRegressor\n",
    "ridge_reg = Ridge(alpha=1)\n",
    "cross_val_score(ridge_reg,X,y).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.01, 0.0001)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###\n",
    "# Elastic Net\n",
    "###\n",
    "from sklearn.linear_model import ElasticNetCV\n",
    "enet_reg = ElasticNetCV(alphas=[.0001, .001, .01,.1,1], l1_ratio=[.0001, .001, .01,.1,.5,.9, .99, 1])\n",
    "enet_reg.fit(X,y)\n",
    "enet_reg.alpha_, enet_reg.l1_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.50930439262658389"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(enet_reg,X,y).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elliott/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/elliott/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "# Scaling with Sparsity\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sparse_scaler = StandardScaler(with_mean=False)\n",
    "X_sparse = sparse_scaler.fit_transform(Xraw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<32567x472 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 460029 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.4130743391509582, 0.0073986758019537807)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logistic = LogisticRegression(C=1, # default L2 penalty\n",
    "                              class_weight='balanced')\n",
    "\n",
    "scores = cross_val_score(logistic,\n",
    "                         X_sparse[:1000],\n",
    "                         df1['state'][:1000],\n",
    "                         cv=3,\n",
    "                         n_jobs=3)\n",
    "\n",
    "scores.mean(), scores.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
